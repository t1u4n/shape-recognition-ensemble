{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4e598f06",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAveragePooling2D\n",
    "from keras.utils import np_utils\n",
    "from keras import backend as K\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import numpy as np\n",
    "import random\n",
    "from keras.layers import LeakyReLU\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "#from keras.applications.vgg16 import preprocess_input\n",
    "from keras.models import Model\n",
    "import sys\n",
    "import tensorflow as tf\n",
    "import pathlib\n",
    "from shutil import copy\n",
    "import tensorflow_io as tfio "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "68f6dd9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "AUTOTUNE = tf.data.experimental.AUTOTUNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "2da58e8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[PhysicalDevice(name='/physical_device:GPU:0', device_type='GPU')]"
      ]
     },
     "execution_count": 272,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.config.experimental.list_physical_devices('GPU')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54543451",
   "metadata": {},
   "source": [
    "### SKIP, FOR file class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9597a6ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#file name, below are classify images\n",
    "\n",
    "#file_names = sorted(item.name for item in pathlib.Path('F:/xlbsData/data/a2/raw').glob('*/') if item.is_dir())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "4bdc9032",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#stuff_path=[str(path) for path in list(pathlib.Path('F:/xlbsData/final/animal_100').glob('*/')) ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "969e7a8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#i=0\n",
    "#k=1\n",
    "#for stuff in stuff_path:\n",
    "#    to_path='F:/xlbsData/data/a1/sin/'+file_names[i]\n",
    "#    copy(stuff, to_path)\n",
    "#    if(k%100==0):\n",
    "#        i+=1\n",
    "#    k=k+1\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0686d36",
   "metadata": {},
   "source": [
    "### create dictionarty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6b1261ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "file_names = sorted(item.name for item in pathlib.Path('F:/xlbsData/data/a2/raw').glob('*/') if item.is_dir())\n",
    "label_to_index = dict((name, index) for index, name in enumerate(file_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc4b558",
   "metadata": {},
   "source": [
    "### create dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "4a930d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess1(path, label):\n",
    "    # read image\n",
    "    image_raw = tf.io.read_file(path['raw_input']) \n",
    "    image_sin = tf.io.read_file(path['sin_input'])\n",
    "    #decode \n",
    "    #image_sin = tf.image.decode_jpeg(image_sin, channels=3)\n",
    "    image_raw=tfio.experimental.image.decode_tiff(image_raw)\n",
    "    image_sin = tfio.experimental.image.decode_tiff(image_sin)\n",
    "    # rsize o the same input size of resnet \n",
    "    image_raw = tf.image.resize(image_raw, [100, 100]) \n",
    "    image_sin = tf.image.resize(image_sin, [100, 100])\n",
    "    image_raw= image_raw[:,:,0:3]\n",
    "    image_sin= image_sin[:,:,0:3]\n",
    "     # normalize\n",
    "    image_raw /= 255.0 \n",
    "    image_sin /= 255.0 \n",
    "    return {'raw_input':image_raw,'sin_input':image_sin}, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "de14c0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess2(path, label):\n",
    "    # read image\n",
    "    image_raw = tf.io.read_file(path['raw_input']) \n",
    "    image_sin = tf.io.read_file(path['sin_input'])\n",
    "    #decode \n",
    "    image_sin = tf.image.decode_jpeg(image_sin, channels=3)\n",
    "    image_raw=tfio.experimental.image.decode_tiff(image_raw)\n",
    "    # rsize o the same input size of resnet \n",
    "    image_raw = tf.image.resize(image_raw, [100, 100]) \n",
    "    image_sin = tf.image.resize(image_sin, [100, 100])\n",
    "    image_raw= image_raw[:,:,0:3]\n",
    "    image_sin= image_sin[:,:,0:3]\n",
    "     # normalize\n",
    "    image_raw /= 255.0 \n",
    "    image_sin /= 255.0 \n",
    "    return {'raw_input':image_raw,'sin_input':image_sin}, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "948c4590",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataset(raw,sin,target,number):\n",
    "    #get the path to dataset\n",
    "    raw_path_r = pathlib.Path(raw)\n",
    "    #get the last two level of the whole path , like damage/111.jpeg or no_damage/11111.jpeg\n",
    "    raw_path = list(raw_path_r.glob('*/*')) \n",
    "    #transform all path to string, preparing for reading \n",
    "    raw_path = [str(path) for path in raw_path]\n",
    "        #get the path to dataset\n",
    "    sin_path = pathlib.Path(sin)\n",
    "    #get the last two level of the whole path , like damage/111.jpeg or no_damage/11111.jpeg\n",
    "    sin_path = list(sin_path.glob('*/*')) \n",
    "    #transform all path to string, preparing for reading \n",
    "    sin_path = [str(path) for path in sin_path]\n",
    "        #get the label, damage or no_damage\n",
    "    label_names_train = sorted(item.name for item in raw_path_r.glob('*/') if item.is_dir())\n",
    "    #transform damage to 0, no_damage to 1\n",
    "    all_image_labels_train = [label_to_index[pathlib.Path(path).parent.name] for path in raw_path]\n",
    "    #get the data path and label\n",
    "    ds_train = tf.data.Dataset.from_tensor_slices(({'raw_input':raw_path,'sin_input':sin_path}, all_image_labels_train))\n",
    "    #preprocess fuciton, transform the data path to data and other preprocess\n",
    "    if (number==1):\n",
    "        ds_train=ds_train.map(preprocess2)\n",
    "    else:\n",
    "        ds_train=ds_train.map(preprocess1)\n",
    "    return ds_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "005309ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_2=get_dataset(a2_raw,a2_sin,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "57eabca1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ds_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "a7217ebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for element in ds_2.take(1).as_numpy_iterator():\n",
    "##    print(list(element[0]['raw_input']))\n",
    " #   plt.imshow(element[0]['raw_input'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "1a80aeda",
   "metadata": {},
   "outputs": [],
   "source": [
    "a1_raw='E:/AAA/data/a1/raw'\n",
    "a1_sin='E:/AAA/data/a1/sin'\n",
    "a2_raw='E:/AAA/data/a2/raw'\n",
    "a2_sin='E:/AAA/data/a2/sin'\n",
    "a3_raw='E:/AAA/data/a3/raw'\n",
    "a3_sin='E:/AAA/data/a3/sin'\n",
    "a4_raw='E:/AAA/data/a4/raw'\n",
    "a4_sin='E:/AAA/data/a4/sin'\n",
    "a5_raw='E:/AAA/data/a5/raw'\n",
    "a5_sin='E:/AAA/data/a5/sin'\n",
    "target='E:/AAA/data/a1/raw'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "c083742a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_1=get_dataset(a1_raw,a1_sin,target,1)\n",
    "ds_2=get_dataset(a2_raw,a2_sin,target,2)\n",
    "ds_3=get_dataset(a3_raw,a3_sin,target,3)\n",
    "ds_4=get_dataset(a4_raw,a4_sin,target,4)\n",
    "ds_5=get_dataset(a5_raw,a5_sin,target,5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6541d9bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds12=ds_1.concatenate(ds_2)\n",
    "ds123=ds12.concatenate(ds_3)\n",
    "ds1234=ds123.concatenate(ds_4)\n",
    "ds_all=ds1234.concatenate(ds_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "e55498ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_all_shuffle=ds_all.shuffle(10000,seed=777)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "8f9ae826",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds_train=ds_all_shuffle.skip(2000)\n",
    "ds_t_v=ds_all_shuffle.take(2000)\n",
    "ds_test=ds_t_v.take(1000)\n",
    "ds_validation=ds_t_v.skip(1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "d92fee8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#i=0\n",
    "#for element in ds12345.as_numpy_iterator():\n",
    "#    i+=1\n",
    "#    print(i)\n",
    "#print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "c28e7710",
   "metadata": {},
   "outputs": [],
   "source": [
    "#for element in ds12345.take(1).as_numpy_iterator():\n",
    "  #print(np.shape(element))\n",
    " #   print(element)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45685c09",
   "metadata": {},
   "source": [
    "### model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "8a651ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model1_1=tf.keras.applications.ResNet50V2(pooling=max,include_top=False,input_shape=(100,100,3))\n",
    "base_model1_2=tf.keras.applications.ResNet50V2(pooling=max,include_top=False,input_shape=(100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "db772c03",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model1_1._name = \"res1\"\n",
    "base_model1_2._name=\"res2\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "e241220d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"res2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_8 (InputLayer)            [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)       (None, 106, 106, 3)  0           input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "conv1_conv (Conv2D)             (None, 50, 50, 64)   9472        conv1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pad (ZeroPadding2D)       (None, 52, 52, 64)   0           conv1_conv[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "pool1_pool (MaxPooling2D)       (None, 25, 25, 64)   0           pool1_pad[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_bn (BatchNo (None, 25, 25, 64)   256         pool1_pool[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_preact_relu (Activ (None, 25, 25, 64)   0           conv2_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_conv (Conv2D)    (None, 25, 25, 64)   4096        conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_1_relu (Activation (None, 25, 25, 64)   0           conv2_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_pad (ZeroPadding (None, 27, 27, 64)   0           conv2_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_conv (Conv2D)    (None, 25, 25, 64)   36864       conv2_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_2_relu (Activation (None, 25, 25, 64)   0           conv2_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_0_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block1_out (Add)          (None, 25, 25, 256)  0           conv2_block1_0_conv[0][0]        \n",
      "                                                                 conv2_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_bn (BatchNo (None, 25, 25, 256)  1024        conv2_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_preact_relu (Activ (None, 25, 25, 256)  0           conv2_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_conv (Conv2D)    (None, 25, 25, 64)   16384       conv2_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_1_relu (Activation (None, 25, 25, 64)   0           conv2_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_pad (ZeroPadding (None, 27, 27, 64)   0           conv2_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_conv (Conv2D)    (None, 25, 25, 64)   36864       conv2_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_2_relu (Activation (None, 25, 25, 64)   0           conv2_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_3_conv (Conv2D)    (None, 25, 25, 256)  16640       conv2_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block2_out (Add)          (None, 25, 25, 256)  0           conv2_block1_out[0][0]           \n",
      "                                                                 conv2_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_bn (BatchNo (None, 25, 25, 256)  1024        conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_preact_relu (Activ (None, 25, 25, 256)  0           conv2_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_conv (Conv2D)    (None, 25, 25, 64)   16384       conv2_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_bn (BatchNormali (None, 25, 25, 64)   256         conv2_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_1_relu (Activation (None, 25, 25, 64)   0           conv2_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_pad (ZeroPadding (None, 27, 27, 64)   0           conv2_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_conv (Conv2D)    (None, 13, 13, 64)   36864       conv2_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_bn (BatchNormali (None, 13, 13, 64)   256         conv2_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_2_relu (Activation (None, 13, 13, 64)   0           conv2_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_9 (MaxPooling2D)  (None, 13, 13, 256)  0           conv2_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_3_conv (Conv2D)    (None, 13, 13, 256)  16640       conv2_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv2_block3_out (Add)          (None, 13, 13, 256)  0           max_pooling2d_9[0][0]            \n",
      "                                                                 conv2_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_bn (BatchNo (None, 13, 13, 256)  1024        conv2_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_preact_relu (Activ (None, 13, 13, 256)  0           conv3_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_conv (Conv2D)    (None, 13, 13, 128)  32768       conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_1_relu (Activation (None, 13, 13, 128)  0           conv3_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_pad (ZeroPadding (None, 15, 15, 128)  0           conv3_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_conv (Conv2D)    (None, 13, 13, 128)  147456      conv3_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_2_relu (Activation (None, 13, 13, 128)  0           conv3_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_0_conv (Conv2D)    (None, 13, 13, 512)  131584      conv3_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block1_out (Add)          (None, 13, 13, 512)  0           conv3_block1_0_conv[0][0]        \n",
      "                                                                 conv3_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_bn (BatchNo (None, 13, 13, 512)  2048        conv3_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_preact_relu (Activ (None, 13, 13, 512)  0           conv3_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_conv (Conv2D)    (None, 13, 13, 128)  65536       conv3_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_1_relu (Activation (None, 13, 13, 128)  0           conv3_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_pad (ZeroPadding (None, 15, 15, 128)  0           conv3_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_conv (Conv2D)    (None, 13, 13, 128)  147456      conv3_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_2_relu (Activation (None, 13, 13, 128)  0           conv3_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block2_out (Add)          (None, 13, 13, 512)  0           conv3_block1_out[0][0]           \n",
      "                                                                 conv3_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_bn (BatchNo (None, 13, 13, 512)  2048        conv3_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_preact_relu (Activ (None, 13, 13, 512)  0           conv3_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_conv (Conv2D)    (None, 13, 13, 128)  65536       conv3_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_1_relu (Activation (None, 13, 13, 128)  0           conv3_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_pad (ZeroPadding (None, 15, 15, 128)  0           conv3_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_conv (Conv2D)    (None, 13, 13, 128)  147456      conv3_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_2_relu (Activation (None, 13, 13, 128)  0           conv3_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_3_conv (Conv2D)    (None, 13, 13, 512)  66048       conv3_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block3_out (Add)          (None, 13, 13, 512)  0           conv3_block2_out[0][0]           \n",
      "                                                                 conv3_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_bn (BatchNo (None, 13, 13, 512)  2048        conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_preact_relu (Activ (None, 13, 13, 512)  0           conv3_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_conv (Conv2D)    (None, 13, 13, 128)  65536       conv3_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_bn (BatchNormali (None, 13, 13, 128)  512         conv3_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_1_relu (Activation (None, 13, 13, 128)  0           conv3_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_pad (ZeroPadding (None, 15, 15, 128)  0           conv3_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_conv (Conv2D)    (None, 7, 7, 128)    147456      conv3_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_bn (BatchNormali (None, 7, 7, 128)    512         conv3_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_2_relu (Activation (None, 7, 7, 128)    0           conv3_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_10 (MaxPooling2D) (None, 7, 7, 512)    0           conv3_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_3_conv (Conv2D)    (None, 7, 7, 512)    66048       conv3_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv3_block4_out (Add)          (None, 7, 7, 512)    0           max_pooling2d_10[0][0]           \n",
      "                                                                 conv3_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_bn (BatchNo (None, 7, 7, 512)    2048        conv3_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_preact_relu (Activ (None, 7, 7, 512)    0           conv4_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_conv (Conv2D)    (None, 7, 7, 256)    131072      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_1_relu (Activation (None, 7, 7, 256)    0           conv4_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_pad (ZeroPadding (None, 9, 9, 256)    0           conv4_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_2_relu (Activation (None, 7, 7, 256)    0           conv4_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_0_conv (Conv2D)    (None, 7, 7, 1024)   525312      conv4_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block1_out (Add)          (None, 7, 7, 1024)   0           conv4_block1_0_conv[0][0]        \n",
      "                                                                 conv4_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_preact_relu (Activ (None, 7, 7, 1024)   0           conv4_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_conv (Conv2D)    (None, 7, 7, 256)    262144      conv4_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_1_relu (Activation (None, 7, 7, 256)    0           conv4_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_pad (ZeroPadding (None, 9, 9, 256)    0           conv4_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_2_relu (Activation (None, 7, 7, 256)    0           conv4_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block2_out (Add)          (None, 7, 7, 1024)   0           conv4_block1_out[0][0]           \n",
      "                                                                 conv4_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_preact_relu (Activ (None, 7, 7, 1024)   0           conv4_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_conv (Conv2D)    (None, 7, 7, 256)    262144      conv4_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_1_relu (Activation (None, 7, 7, 256)    0           conv4_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_pad (ZeroPadding (None, 9, 9, 256)    0           conv4_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_2_relu (Activation (None, 7, 7, 256)    0           conv4_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block3_out (Add)          (None, 7, 7, 1024)   0           conv4_block2_out[0][0]           \n",
      "                                                                 conv4_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_preact_relu (Activ (None, 7, 7, 1024)   0           conv4_block4_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_conv (Conv2D)    (None, 7, 7, 256)    262144      conv4_block4_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_1_relu (Activation (None, 7, 7, 256)    0           conv4_block4_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_pad (ZeroPadding (None, 9, 9, 256)    0           conv4_block4_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block4_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block4_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_2_relu (Activation (None, 7, 7, 256)    0           conv4_block4_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block4_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block4_out (Add)          (None, 7, 7, 1024)   0           conv4_block3_out[0][0]           \n",
      "                                                                 conv4_block4_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block4_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_preact_relu (Activ (None, 7, 7, 1024)   0           conv4_block5_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_conv (Conv2D)    (None, 7, 7, 256)    262144      conv4_block5_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_1_relu (Activation (None, 7, 7, 256)    0           conv4_block5_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_pad (ZeroPadding (None, 9, 9, 256)    0           conv4_block5_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_conv (Conv2D)    (None, 7, 7, 256)    589824      conv4_block5_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block5_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_2_relu (Activation (None, 7, 7, 256)    0           conv4_block5_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_3_conv (Conv2D)    (None, 7, 7, 1024)   263168      conv4_block5_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block5_out (Add)          (None, 7, 7, 1024)   0           conv4_block4_out[0][0]           \n",
      "                                                                 conv4_block5_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_bn (BatchNo (None, 7, 7, 1024)   4096        conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_preact_relu (Activ (None, 7, 7, 1024)   0           conv4_block6_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_conv (Conv2D)    (None, 7, 7, 256)    262144      conv4_block6_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_bn (BatchNormali (None, 7, 7, 256)    1024        conv4_block6_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_1_relu (Activation (None, 7, 7, 256)    0           conv4_block6_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_pad (ZeroPadding (None, 9, 9, 256)    0           conv4_block6_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_conv (Conv2D)    (None, 4, 4, 256)    589824      conv4_block6_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_bn (BatchNormali (None, 4, 4, 256)    1024        conv4_block6_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_2_relu (Activation (None, 4, 4, 256)    0           conv4_block6_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_11 (MaxPooling2D) (None, 4, 4, 1024)   0           conv4_block5_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_3_conv (Conv2D)    (None, 4, 4, 1024)   263168      conv4_block6_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv4_block6_out (Add)          (None, 4, 4, 1024)   0           max_pooling2d_11[0][0]           \n",
      "                                                                 conv4_block6_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_bn (BatchNo (None, 4, 4, 1024)   4096        conv4_block6_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_preact_relu (Activ (None, 4, 4, 1024)   0           conv5_block1_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_conv (Conv2D)    (None, 4, 4, 512)    524288      conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_1_relu (Activation (None, 4, 4, 512)    0           conv5_block1_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_pad (ZeroPadding (None, 6, 6, 512)    0           conv5_block1_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_conv (Conv2D)    (None, 4, 4, 512)    2359296     conv5_block1_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block1_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_2_relu (Activation (None, 4, 4, 512)    0           conv5_block1_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_0_conv (Conv2D)    (None, 4, 4, 2048)   2099200     conv5_block1_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block1_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block1_out (Add)          (None, 4, 4, 2048)   0           conv5_block1_0_conv[0][0]        \n",
      "                                                                 conv5_block1_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_bn (BatchNo (None, 4, 4, 2048)   8192        conv5_block1_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_preact_relu (Activ (None, 4, 4, 2048)   0           conv5_block2_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_conv (Conv2D)    (None, 4, 4, 512)    1048576     conv5_block2_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_1_relu (Activation (None, 4, 4, 512)    0           conv5_block2_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_pad (ZeroPadding (None, 6, 6, 512)    0           conv5_block2_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_conv (Conv2D)    (None, 4, 4, 512)    2359296     conv5_block2_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block2_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_2_relu (Activation (None, 4, 4, 512)    0           conv5_block2_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block2_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block2_out (Add)          (None, 4, 4, 2048)   0           conv5_block1_out[0][0]           \n",
      "                                                                 conv5_block2_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_bn (BatchNo (None, 4, 4, 2048)   8192        conv5_block2_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_preact_relu (Activ (None, 4, 4, 2048)   0           conv5_block3_preact_bn[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_conv (Conv2D)    (None, 4, 4, 512)    1048576     conv5_block3_preact_relu[0][0]   \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_1_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_1_relu (Activation (None, 4, 4, 512)    0           conv5_block3_1_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_pad (ZeroPadding (None, 6, 6, 512)    0           conv5_block3_1_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_conv (Conv2D)    (None, 4, 4, 512)    2359296     conv5_block3_2_pad[0][0]         \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_bn (BatchNormali (None, 4, 4, 512)    2048        conv5_block3_2_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_2_relu (Activation (None, 4, 4, 512)    0           conv5_block3_2_bn[0][0]          \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_3_conv (Conv2D)    (None, 4, 4, 2048)   1050624     conv5_block3_2_relu[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "conv5_block3_out (Add)          (None, 4, 4, 2048)   0           conv5_block2_out[0][0]           \n",
      "                                                                 conv5_block3_3_conv[0][0]        \n",
      "__________________________________________________________________________________________________\n",
      "post_bn (BatchNormalization)    (None, 4, 4, 2048)   8192        conv5_block3_out[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "post_relu (Activation)          (None, 4, 4, 2048)   0           post_bn[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 23,564,800\n",
      "Trainable params: 1,054,720\n",
      "Non-trainable params: 22,510,080\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "base_model1_2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "93347ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model2=tf.keras.applications.Xception(pooling=max,include_top=False,input_shape=(100,100,3))\n",
    "base_model3=tf.keras.applications.VGG16(pooling=max,include_top=False,input_shape=(100,100,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "efb6b916",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model1_1.layers[:]:\n",
    "  layer.trainable=False\n",
    "for layer in base_model1_2.layers[:]:\n",
    "  layer.trainable=False\n",
    "for layer in base_model2.layers[:]:\n",
    "  layer.trainable=False\n",
    "for layer in base_model3.layers[:]:\n",
    "  layer.trainable=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "c96769a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "for layer in base_model1_1.layers[-5:]:\n",
    "    layer.trainable=True\n",
    "for layer in base_model1_2.layers[-5:]:\n",
    "    layer.trainable=True\n",
    "for layer in base_model2.layers[-5:]:\n",
    "    layer.trainable=True\n",
    "for layer in base_model3.layers[-3:]:\n",
    "    layer.trainable=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "eeeff36d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#base_model2.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "b50fb404",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_raw = tf.keras.Input(shape=(100, 100,3),name='raw_input')\n",
    "inputs_sin = tf.keras.Input(shape=(100, 100,3),name='sin_input')\n",
    "x1 = base_model1_1(inputs_raw)\n",
    "x2 = base_model1_2(inputs_sin)\n",
    "\n",
    "concat = tf.keras.layers.concatenate([x1,x2])\n",
    "    #x = base_model(inputs)\n",
    "    #use the gloval average pooling\n",
    "\n",
    "GlobalAveragePooling2D = tf.keras.layers.GlobalAveragePooling2D() \n",
    "x=GlobalAveragePooling2D(concat)\n",
    "    #use dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    #add a layer with 128 nodes\n",
    "x=tf.keras.layers.Dense(4096,activation='relu')(x)\n",
    "    #use dropout\n",
    "x = tf.keras.layers.Dropout(0.5)(x)\n",
    "    #add a layer with 64 nodes\n",
    "x=tf.keras.layers.Dense(4096,activation='relu')(x)\n",
    "\n",
    "outputs=tf.keras.layers.Dense(20,activation='softmax')(x)\n",
    "model = tf.keras.Model(inputs=[inputs_raw,inputs_sin], outputs=[outputs])#compile the model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.00007),\n",
    "                loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "                metrics=['accuracy'])\n",
    "    \n",
    "\n",
    "#history = model.fit(ds_train_aug.shuffle(4096,reshuffle_each_iteration=False).batch(32).prefetch(2),\n",
    "#    epochs=10,validation_data=ds_validation.batch(256).prefetch(2),callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "424c0bd3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "raw_input (InputLayer)          [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "sin_input (InputLayer)          [(None, 100, 100, 3) 0                                            \n",
      "__________________________________________________________________________________________________\n",
      "res1 (Functional)               (None, 4, 4, 2048)   23564800    raw_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "res2 (Functional)               (None, 4, 4, 2048)   23564800    sin_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 4, 4, 4096)   0           res1[4][0]                       \n",
      "                                                                 res2[4][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "global_average_pooling2d_4 (Glo (None, 4096)         0           concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_8 (Dropout)             (None, 4096)         0           global_average_pooling2d_4[0][0] \n",
      "__________________________________________________________________________________________________\n",
      "dense_12 (Dense)                (None, 4096)         16781312    dropout_8[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dropout_9 (Dropout)             (None, 4096)         0           dense_12[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "dense_13 (Dense)                (None, 4096)         16781312    dropout_9[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_14 (Dense)                (None, 20)           81940       dense_13[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 80,774,164\n",
      "Trainable params: 35,754,004\n",
      "Non-trainable params: 45,020,160\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42f9e7af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/150\n",
      "250/250 [==============================] - 39s 69ms/step - loss: 1.7371 - accuracy: 0.4710 - val_loss: 0.8407 - val_accuracy: 0.7470\n",
      "Epoch 2/150\n",
      "250/250 [==============================] - 23s 67ms/step - loss: 1.0434 - accuracy: 0.6656 - val_loss: 0.5644 - val_accuracy: 0.8370\n",
      "Epoch 3/150\n",
      "250/250 [==============================] - 23s 65ms/step - loss: 0.8210 - accuracy: 0.7410 - val_loss: 0.3550 - val_accuracy: 0.8870\n",
      "Epoch 4/150\n",
      "250/250 [==============================] - 23s 65ms/step - loss: 0.6532 - accuracy: 0.7872 - val_loss: 0.3010 - val_accuracy: 0.9000\n",
      "Epoch 5/150\n",
      "250/250 [==============================] - 24s 66ms/step - loss: 0.5500 - accuracy: 0.8210 - val_loss: 0.2078 - val_accuracy: 0.9390\n",
      "Epoch 6/150\n",
      "250/250 [==============================] - 24s 67ms/step - loss: 0.4664 - accuracy: 0.8438 - val_loss: 0.1647 - val_accuracy: 0.9500\n",
      "Epoch 7/150\n",
      "250/250 [==============================] - 34s 106ms/step - loss: 0.3904 - accuracy: 0.8723 - val_loss: 0.1243 - val_accuracy: 0.9640\n",
      "Epoch 8/150\n",
      "250/250 [==============================] - 24s 65ms/step - loss: 0.3501 - accuracy: 0.8831 - val_loss: 0.0862 - val_accuracy: 0.9750\n",
      "Epoch 9/150\n",
      "250/250 [==============================] - 34s 107ms/step - loss: 0.3020 - accuracy: 0.8980 - val_loss: 0.0520 - val_accuracy: 0.9900\n",
      "Epoch 10/150\n",
      "250/250 [==============================] - 34s 107ms/step - loss: 0.2412 - accuracy: 0.9200 - val_loss: 0.0521 - val_accuracy: 0.9860\n",
      "Epoch 11/150\n",
      "250/250 [==============================] - 25s 68ms/step - loss: 0.2226 - accuracy: 0.9234 - val_loss: 0.0239 - val_accuracy: 0.9970\n",
      "Epoch 12/150\n",
      "250/250 [==============================] - 34s 106ms/step - loss: 0.1959 - accuracy: 0.9327 - val_loss: 0.0291 - val_accuracy: 0.9910\n",
      "Epoch 13/150\n",
      "250/250 [==============================] - 34s 107ms/step - loss: 0.1945 - accuracy: 0.9336 - val_loss: 0.0247 - val_accuracy: 0.9940\n",
      "Epoch 14/150\n",
      "250/250 [==============================] - 25s 68ms/step - loss: 0.1664 - accuracy: 0.9425 - val_loss: 0.0236 - val_accuracy: 0.9970\n",
      "Epoch 15/150\n",
      "250/250 [==============================] - 34s 106ms/step - loss: 0.1431 - accuracy: 0.9524 - val_loss: 0.0111 - val_accuracy: 0.9990\n",
      "Epoch 16/150\n",
      "250/250 [==============================] - 34s 106ms/step - loss: 0.1293 - accuracy: 0.9563 - val_loss: 0.0122 - val_accuracy: 0.9970\n",
      "Epoch 17/150\n",
      "250/250 [==============================] - 34s 107ms/step - loss: 0.1301 - accuracy: 0.9549 - val_loss: 0.0116 - val_accuracy: 0.9970\n",
      "Epoch 18/150\n",
      "250/250 [==============================] - 34s 106ms/step - loss: 0.1182 - accuracy: 0.9619 - val_loss: 0.0096 - val_accuracy: 0.9990\n",
      "Epoch 19/150\n",
      "250/250 [==============================] - 24s 67ms/step - loss: 0.1072 - accuracy: 0.9632 - val_loss: 0.0085 - val_accuracy: 0.9990\n",
      "Epoch 20/150\n",
      "250/250 [==============================] - 34s 107ms/step - loss: 0.1068 - accuracy: 0.9626 - val_loss: 0.0055 - val_accuracy: 1.0000\n",
      "Epoch 21/150\n",
      "250/250 [==============================] - 34s 107ms/step - loss: 0.0912 - accuracy: 0.9688 - val_loss: 0.0102 - val_accuracy: 0.9970\n",
      "Epoch 22/150\n",
      "250/250 [==============================] - 34s 107ms/step - loss: 0.0836 - accuracy: 0.9721 - val_loss: 0.0074 - val_accuracy: 0.9970\n",
      "Epoch 23/150\n",
      "250/250 [==============================] - 34s 106ms/step - loss: 0.0997 - accuracy: 0.9670 - val_loss: 0.0057 - val_accuracy: 0.9990\n",
      "Epoch 24/150\n",
      "250/250 [==============================] - 34s 107ms/step - loss: 0.0759 - accuracy: 0.9744 - val_loss: 0.0038 - val_accuracy: 0.9980\n",
      "Epoch 25/150\n",
      "250/250 [==============================] - 35s 106ms/step - loss: 0.0772 - accuracy: 0.9760 - val_loss: 0.0039 - val_accuracy: 0.9990\n",
      "Epoch 26/150\n",
      "250/250 [==============================] - 35s 106ms/step - loss: 0.0762 - accuracy: 0.9743 - val_loss: 0.0041 - val_accuracy: 0.9990\n",
      "Epoch 27/150\n",
      "250/250 [==============================] - 25s 69ms/step - loss: 0.0765 - accuracy: 0.9729 - val_loss: 0.0032 - val_accuracy: 1.0000\n",
      "Epoch 28/150\n",
      "250/250 [==============================] - 34s 106ms/step - loss: 0.0703 - accuracy: 0.9779 - val_loss: 0.0026 - val_accuracy: 1.0000\n",
      "Epoch 29/150\n",
      "250/250 [==============================] - 35s 108ms/step - loss: 0.0762 - accuracy: 0.9751 - val_loss: 0.0030 - val_accuracy: 0.9990\n",
      "Epoch 30/150\n",
      "250/250 [==============================] - 35s 107ms/step - loss: 0.0724 - accuracy: 0.9764 - val_loss: 0.0022 - val_accuracy: 1.0000\n",
      "Epoch 31/150\n",
      "250/250 [==============================] - 34s 106ms/step - loss: 0.0660 - accuracy: 0.9776 - val_loss: 0.0033 - val_accuracy: 0.9990\n",
      "Epoch 32/150\n",
      "250/250 [==============================] - 34s 106ms/step - loss: 0.0586 - accuracy: 0.9791 - val_loss: 0.0017 - val_accuracy: 1.0000\n",
      "Epoch 33/150\n",
      "250/250 [==============================] - 35s 107ms/step - loss: 0.0666 - accuracy: 0.9768 - val_loss: 0.0015 - val_accuracy: 1.0000\n",
      "Epoch 34/150\n",
      "250/250 [==============================] - 34s 107ms/step - loss: 0.0541 - accuracy: 0.9809 - val_loss: 0.0019 - val_accuracy: 0.9990\n",
      "Epoch 35/150\n",
      "250/250 [==============================] - ETA: 0s - loss: 0.0514 - accuracy: 0.9833"
     ]
    }
   ],
   "source": [
    "callback = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=20,restore_best_weights=True)\n",
    "history=model.fit(ds_train.batch(32).prefetch(buffer_size=AUTOTUNE), epochs = 150,verbose=1, validation_data=ds_validation.batch(32).prefetch(buffer_size=AUTOTUNE),callbacks=[callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c7aa41c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
